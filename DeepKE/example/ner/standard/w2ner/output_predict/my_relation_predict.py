import os
import csv
import time
import json
import concurrent.futures
from tqdm import tqdm
from openai import OpenAI
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    filename='relation_processing.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# ä¸¥æ ¼éµå¾ªç”¨æˆ·æä¾›çš„7ç§å…³ç³»ç±»å‹
RELATION_TYPES = [
    "rely", "none", "belg", "b-belg", 
    "syno", "b-rely", "anto","attr", "b-attr"
]

# ç”¨æˆ·æä¾›çš„è¯¦ç»†è§„åˆ™æè¿°ï¼ˆç”¨äºæç¤ºè¯ï¼‰
RULES_DESCRIPTION = """
è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™åˆ†æå…³ç³»ç±»å‹ï¼š
1. **ä¾èµ–å…³ç³» (rely)**: å®ä½“å­˜åœ¨æ˜æ˜¾çš„é€»è¾‘é¡ºåºå…³ç³»ï¼Œheadçš„å­¦ä¹ æˆ–åŠŸèƒ½ä¾èµ–äºtail (ä¾‹å¦‚: headçš„å®ç°/æ•ˆç‡éœ€è¦tailæ”¯æŒ)ã€‚
2. **è¢«ä¾èµ–å…³ç³» (b-rely)**: å®ä½“å­˜åœ¨æ˜æ˜¾çš„é€»è¾‘é¡ºåºå…³ç³»ï¼Œheadè¢«tailä¾èµ– (tailçš„å­¦ä¹ æˆ–åŠŸèƒ½ä¾èµ–äºhead)ã€‚
3. **åŒ…å«å…³ç³» (belg)**: å®ä½“å­˜åœ¨æ˜æ˜¾ä»å±å…³ç³»ï¼Œtailä½œä¸ºæ¦‚å¿µèŒƒç•´åŒ…å«head (æ•´ä½“-éƒ¨åˆ†å…³ç³»)ã€‚
4. **å±äºå…³ç³» (b-belg)**: å®ä½“å­˜åœ¨æ˜æ˜¾ä»å±å…³ç³»ï¼Œheadå±äºtailçš„æ¦‚å¿µèŒƒç•´ (is-aå…³ç³»)ã€‚
5. **åŒä¹‰å…³ç³» (syno)**: headå’Œtailåœ¨ä¸åŒå«æ³•ä¸‹æŒ‡å‘ç›¸åŒæ¦‚å¿µ (åŒä¸€å®ä½“çš„ä¸åŒåç§°)ã€‚
6. **åä¹‰å…³ç³» (anto)**: headå’Œtailåœ¨æ¦‚å¿µå™è¿°ä¸Šå…·æœ‰ç›¸åå«ä¹‰ (è¯­ä¹‰å¯¹ç«‹)ã€‚
7. **æ‹¥æœ‰å…³ç³» (attr)**: tailæ˜¯æè¿°headçš„å±æ€§å®ä½“ (headå…·æœ‰tailå±æ€§)ã€‚
8. **å±æ€§å…³ç³» (b-attr)**: headæ˜¯æè¿°tailçš„å±æ€§å®ä½“ (tailå…·æœ‰headå±æ€§)ã€‚
9. **æ— å…³ç³» (none)**: headå’Œtailä¸å­˜åœ¨ç›´æ¥è¯­ä¹‰å…³è”ã€‚

ä¸¥æ ¼æ³¨æ„äº‹é¡¹ï¼š
- åªèƒ½ä½¿ç”¨ä»¥ä¸Š9ç§å…³ç³»ç±»å‹ï¼Œä¸è¦æ–°å¢æˆ–ä¿®æ”¹
- å…³ç³»åˆ¤æ–­å¿…é¡»åŸºäºå®ä½“é—´å®¢è§‚å­˜åœ¨çš„è¯­ä¹‰å…³ç³»
- æ—¢è€ƒè™‘è¡¨é¢è¯è¯­å…³è”ï¼Œä¹Ÿå…³æ³¨æ·±å±‚æ¦‚å¿µè”ç³»
"""

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
def create_client():
    return OpenAI(
        base_url="https://ark.cn-beijing.volces.com/api/v3",
        api_key=os.environ.get("ARK_API_KEY"),
        timeout=60  # 60ç§’è¶…æ—¶
    )

# ç”Ÿæˆå…³ç³»åˆ†ææç¤ºè¯ï¼ˆæ•´åˆè¯¦ç»†è§„åˆ™ï¼‰
def generate_relation_prompt(item):
    """ç”ŸæˆåŸºäºè§„åˆ™çš„æç¤ºè¯"""
    return f"""
ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„æ•°æ®ç»“æ„ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹è§„åˆ™åˆ†æå¥å­ä¸­"{item['head']}"å’Œ"{item['tail']}"ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼š

{RULES_DESCRIPTION}

å¥å­å†…å®¹ï¼š{item['sentence']}
å¤´éƒ¨å®ä½“ï¼š"{item['head']}" (ä½ç½®ï¼šç¬¬{item['head_offset']}ä¸ªå­—ç¬¦)
å°¾éƒ¨å®ä½“ï¼š"{item['tail']}" (ä½ç½®ï¼šç¬¬{item['tail_offset']}ä¸ªå­—ç¬¦)

åˆ†ææ­¥éª¤ï¼š
1. ç¡®å®šä¸¤ä¸ªå®ä½“ä¹‹é—´æ˜¯å¦å­˜åœ¨è¯­ä¹‰å…³è”
2. å¦‚æœ‰è¯­ä¹‰å…³è”ï¼Œåˆ¤æ–­ç¬¦åˆå“ªç§å…³ç³»ç±»å‹çš„å®šä¹‰
3. å¦‚æ— ç›´æ¥è¯­ä¹‰å…³è”ï¼Œä½¿ç”¨"æ— å…³ç³»"

è¯·ç›´æ¥è¾“å‡ºå…³ç³»ç±»å‹åç§°ï¼š
"""

# è§£æAPIå“åº”å¹¶éªŒè¯å…³ç³»ç±»å‹
def parse_and_validate_relation(response_content):
    """è§£æå¹¶éªŒè¯APIè¿”å›çš„å…³ç³»ç±»å‹"""
    # æå–å“åº”ä¸­çš„å…³ç³»ç±»å‹
    response_content = response_content.strip()
    
    if not response_content:
        return "æ— å…³ç³»"
    
    # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœ‰æ•ˆçš„ç±»å‹åç§°
    for relation in RELATION_TYPES:
        if relation == response_content:
            return relation
    
    # å¤„ç†ç‰¹æ®Šæƒ…å†µ
    for relation in RELATION_TYPES:
        # éƒ¨åˆ†åŒ¹é…æ£€æŸ¥
        if response_content.startswith(relation[:2]):
            return relation
    
    logging.warning(f"æ— æ•ˆå…³ç³»ç±»å‹: {response_content}")
    return "æ— å…³ç³»"

# è°ƒç”¨ç«å±±å¼•æ“APIåˆ†æå…³ç³»
def analyze_relation_with_retry(item, client, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„å…³ç³»åˆ†æAPIè°ƒç”¨"""
    prompt = generate_relation_prompt(item)
    attempts = 0
    
    while attempts < max_retries:
        try:
            # è°ƒç”¨API
            response = client.chat.completions.create(
                model="doubao-1-5-lite-32k-250115",
                messages=[
                    {
                        "role": "system", 
                        "content": f"ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„æ•°æ®ç»“æ„ä¸“å®¶ï¼Œä¸¥æ ¼æŒ‰ç…§è§„åˆ™åˆ†æå…³ç³»ï¼Œåªä½¿ç”¨ä»¥ä¸‹ç±»å‹: {', '.join(RELATION_TYPES)}"
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=10,
                temperature=0.0  # é›¶éšæœºæ€§ç¡®ä¿ç¨³å®šæ€§
            )
            
            # è§£æå’ŒéªŒè¯å“åº”
            response_content = response.choices[0].message.content.strip()
            return parse_and_validate_relation(response_content)
            
        except Exception as e:
            logging.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)} - é‡è¯• {attempts+1}/{max_retries}")
            attempts += 1
            time.sleep(2 ** attempts)  # æŒ‡æ•°é€€é¿
    
    logging.error(f"å…³ç³»åˆ†æå¤±è´¥: {item}")
    return "æ— å…³ç³»"  # é‡è¯•å¤±è´¥åè¿”å›é»˜è®¤å€¼

# å¤„ç†å•ä¸ªæ¡ç›®
def process_item(item, client):
    """å¤„ç†å•ä¸ªæ¡ç›®ï¼Œç”Ÿæˆç¬¦åˆå›¾ç‰‡æ ¼å¼çš„è¾“å‡ºè¡Œ"""
    # ç¡®ä¿ä½ç½®ä¿¡æ¯æ˜¯å­—ç¬¦ä¸²
    head_offset = str(item["head_offset"])
    tail_offset = str(item["tail_offset"])
    
    # è°ƒç”¨APIåˆ†æå…³ç³»
    relation = analyze_relation_with_retry(item, client)
    
    # æŒ‰ç…§å›¾ç‰‡ä¸­çš„æ ¼å¼è¿”å›CSVè¡Œ
    return [
        item["sentence"],
        relation,
        item["head"],
        item["tail"],
        head_offset,
        tail_offset
    ]

# æ‰¹é‡å¤„ç†JSONæ–‡ä»¶å¹¶è¾“å‡ºCSV
def process_json_file(input_file, output_file, concurrency=5):
    """
    å¤„ç†JSONæ–‡ä»¶ï¼Œè¾“å‡ºç¬¦åˆå›¾ç‰‡æ ¼å¼çš„CSV
    :param input_file: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
    :param output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
    :param concurrency: å¹¶å‘æ•°
    """
    # éªŒè¯APIå¯†é’¥
    if not os.environ.get("ARK_API_KEY"):
        print("âŒ é”™è¯¯: è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ ARK_API_KEY")
        return
    
    # è¯»å–è¾“å…¥æ–‡ä»¶
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return
    
    print(f"âœ… å·²åŠ è½½ {len(data)} æ¡è®°å½•")
    print(f"âš¡ å¼€å§‹å¤„ç†ï¼Œå¹¶å‘æ•°: {concurrency}")
    print(f"ğŸ“ ä½¿ç”¨å…³ç³»ç±»å‹: {', '.join(RELATION_TYPES)}")
    
    client = create_client()
    processed_rows = []
    
    # æ·»åŠ CSVæ ‡é¢˜è¡Œï¼ˆä¸å›¾ç‰‡ä¸€è‡´ï¼‰
    header = ["sentence", "relation", "head", "tail", "head_offset", "tail_offset"]
    processed_rows.append(header)
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:
        # å‡†å¤‡ä»»åŠ¡
        futures = {
            executor.submit(process_item, item, client): item
            for item in data
        }
        
        # å¤„ç†ç»“æœå¸¦è¿›åº¦æ¡
        completed = tqdm(
            concurrent.futures.as_completed(futures),
            total=len(data),
            desc="åˆ†æè¯­ä¹‰å…³ç³»"
        )
        
        for future in completed:
            try:
                result = future.result()
                processed_rows.append(result)
            except Exception as e:
                logging.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                # æ·»åŠ é»˜è®¤å€¼ä½œä¸ºå›é€€
                processed_rows.append([
                    "å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—", 
                    "æ— å…³ç³»", 
                    "N/A", 
                    "N/A", 
                    "0", 
                    "0"
                ])
    
    # ä¿å­˜ä¸ºCSVæ–‡ä»¶ï¼ˆä¸å›¾ç‰‡æ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
    try:
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(processed_rows)
        print(f"âœ… å¤„ç†å®Œæˆ! CSVç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # ç»Ÿè®¡å…³ç³»åˆ†å¸ƒ
        relation_counts = {rel: 0 for rel in RELATION_TYPES}
        total_rows = len(processed_rows) - 1  # å‡å»æ ‡é¢˜è¡Œ
        
        if total_rows > 0:
            for row in processed_rows[1:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
                relation = row[1]
                if relation in relation_counts:
                    relation_counts[relation] += 1
        
        print("\nğŸ“Š å…³ç³»ç±»å‹åˆ†å¸ƒ:")
        for rel in RELATION_TYPES:
            count = relation_counts[rel]
            percent = count / total_rows * 100 if total_rows > 0 else 0
            print(f"- {rel}: {count} æ¡ ({percent:.1f}%)")
            
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # é…ç½®è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„
    input_file = "train_predict.json"      # æ›¿æ¢ä¸ºæ‚¨çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
    output_file = "relation_predict.csv"      # è¾“å‡ºCSVæ–‡ä»¶ï¼ˆä¸å›¾ç‰‡ä¸€è‡´ï¼‰
    
    # æ‰§è¡Œå¤„ç†
    process_json_file(input_file, output_file, concurrency=5)