#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†å›¾è°±æ•°æ®ç”Ÿæˆå™¨ - ä¼˜åŒ–ç‰ˆ
ç”Ÿæˆé«˜è´¨é‡çš„çŸ¥è¯†å›¾è°±æ„å»ºè®­ç»ƒæ•°æ®
"""

import os
import time
import concurrent.futures
from openai import OpenAI
from tqdm import tqdm
import random
import logging
import re
import json
from collections import Counter

# ç¦ç”¨HTTPè¯·æ±‚æ—¥å¿—
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)

# ============================= é…ç½® =============================
class Config:
    API_KEY = os.environ.get("ARK_API_KEY")
    BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
    MODEL = "doubao-1-5-lite-32k-250115"
    NUM_RECORDS = 3000
    CONCURRENCY = 30  # è¿›ä¸€æ­¥å¢åŠ å¹¶å‘æ•°æé«˜ååé‡
    OUTPUT_FILE = "/root/KG/generate_data/data_backups/knowledge_graph_sentences.txt"
    TIMEOUT = 30      # å‡å°‘è¶…æ—¶æ—¶é—´æé«˜æ•ˆç‡
    RETRY_COUNT = 2   # å‡å°‘é‡è¯•æ¬¡æ•°é™ä½å»¶è¿Ÿ
    DELAY_BETWEEN_REQUESTS = 0  # ç§»é™¤å»¶è¿Ÿæé«˜é€Ÿåº¦

# ========================= çŸ¥è¯†åº“ =============================
KNOWLEDGE_GRAPH_BASE = {
    "æ•°æ®ç»“æ„": [
        "æ•°ç»„", "é“¾è¡¨", "æ ˆ", "é˜Ÿåˆ—", "å“ˆå¸Œè¡¨", "æ ‘", "å›¾", "å †", "é›†åˆ", "æ˜ å°„",
        "åŒå‘é“¾è¡¨", "å¾ªç¯é“¾è¡¨", "äºŒå‰æ ‘", "äºŒå‰æœç´¢æ ‘", "AVLæ ‘", "çº¢é»‘æ ‘",
        "Bæ ‘", "B+æ ‘", "å­—å…¸æ ‘", "çº¿æ®µæ ‘", "å¹¶æŸ¥é›†", "ä¼˜å…ˆé˜Ÿåˆ—", "åŒç«¯é˜Ÿåˆ—"
    ],
    "ç®—æ³•": [
        "å†’æ³¡æ’åº", "æ’å…¥æ’åº", "é€‰æ‹©æ’åº", "å½’å¹¶æ’åº", "å¿«é€Ÿæ’åº", "å †æ’åº",
        "è®¡æ•°æ’åº", "åŸºæ•°æ’åº", "æ¡¶æ’åº", "æ·±åº¦ä¼˜å…ˆæœç´¢", "å¹¿åº¦ä¼˜å…ˆæœç´¢",
        "äºŒåˆ†æŸ¥æ‰¾", "çº¿æ€§æŸ¥æ‰¾", "å“ˆå¸ŒæŸ¥æ‰¾", "Dijkstraç®—æ³•", "Floydç®—æ³•",
        "Kruskalç®—æ³•", "Primç®—æ³•", "æ‹“æ‰‘æ’åº", "åŠ¨æ€è§„åˆ’", "è´ªå¿ƒç®—æ³•", "åˆ†æ²»ç®—æ³•"
    ],
    "ç®—æ³•ç‰¹æ€§": [
        "æ—¶é—´å¤æ‚åº¦", "ç©ºé—´å¤æ‚åº¦", "ç¨³å®šæ€§", "åŸåœ°æ’åº", "æ¯”è¾ƒæ’åº", "éæ¯”è¾ƒæ’åº",
        "é€’å½’", "è¿­ä»£", "åˆ†æ²»", "è´ªå¿ƒ", "åŠ¨æ€è§„åˆ’", "å›æº¯", "å‰ªæ", "ä¼˜åŒ–"
    ],
    "æ•°æ®ç»“æ„ç‰¹æ€§": [
        "çº¿æ€§ç»“æ„", "éçº¿æ€§ç»“æ„", "é¡ºåºå­˜å‚¨", "é“¾å¼å­˜å‚¨", "éšæœºè®¿é—®", "é¡ºåºè®¿é—®",
        "LIFO", "FIFO", "å¹³è¡¡", "å®Œå…¨", "æ»¡", "æœ‰åº", "æ— åº", "è¿é€š", "å¼ºè¿é€š"
    ],
    "æ“ä½œç±»å‹": [
        "æ’å…¥", "åˆ é™¤", "æŸ¥æ‰¾", "éå†", "æ’åº", "åˆå¹¶", "åˆ†å‰²", "æ—‹è½¬",
        "å¹³è¡¡", "å‹ç¼©", "æ‰©å®¹", "ç¼©å®¹", "åˆå§‹åŒ–", "é”€æ¯", "å¤åˆ¶", "ç§»åŠ¨"
    ],
    "åº”ç”¨åœºæ™¯": [
        "æ•°æ®åº“ç´¢å¼•", "ç¼–è¯‘å™¨", "æ“ä½œç³»ç»Ÿ", "ç½‘ç»œè·¯ç”±", "å›¾åƒå¤„ç†", "æœºå™¨å­¦ä¹ ",
        "æœç´¢å¼•æ“", "ç¼“å­˜ç³»ç»Ÿ", "æ–‡ä»¶ç³»ç»Ÿ", "å†…å­˜ç®¡ç†", "ä»»åŠ¡è°ƒåº¦", "è´Ÿè½½å‡è¡¡"
    ]
}

# ========================= æ ¸å¿ƒå‡½æ•° =============================
def create_client():
    return OpenAI(base_url=Config.BASE_URL, api_key=Config.API_KEY, timeout=Config.TIMEOUT)

def generate_kg_optimized_prompts(num_records):
    """ç”Ÿæˆé’ˆå¯¹çŸ¥è¯†å›¾è°±æ„å»ºä¼˜åŒ–çš„æç¤ºè¯"""
    
    # å…³ç³»å‹æç¤ºæ¨¡æ¿ (40%)
    relation_templates = [
        "è¯·ç”¨ä¸€å¥è¯æè¿°{entity1}å’Œ{entity2}ä¹‹é—´çš„å…³ç³»",
        "ç®€è¿°{entity1}å¦‚ä½•ä¸{entity2}ç›¸å…³è”",
        "è§£é‡Š{entity1}å¯¹{entity2}çš„ä½œç”¨æˆ–å½±å“",
        "è¯´æ˜{entity1}å’Œ{entity2}çš„åŒºåˆ«æˆ–è”ç³»",
        "æè¿°{entity1}åœ¨{entity2}ä¸­çš„åº”ç”¨",
        "æ¯”è¾ƒ{entity1}ä¸{entity2}çš„æ€§èƒ½ç‰¹ç‚¹",
        "åˆ†æ{entity1}å’Œ{entity2}çš„é€‚ç”¨åœºæ™¯å·®å¼‚",
        "é˜è¿°{entity1}ç›¸å¯¹äº{entity2}çš„ä¼˜åŠ¿",
        "è¯´æ˜{entity1}ä¸{entity2}çš„å®ç°å¤æ‚åº¦å¯¹æ¯”"
    ]
    
    # å®ä½“æè¿°å‹æ¨¡æ¿ (30%)
    entity_templates = [
        "è¯·æè¿°{entity}çš„ä¸»è¦ç‰¹å¾å’Œåº”ç”¨åœºæ™¯",
        "ç®€è¿°{entity}çš„å·¥ä½œåŸç†å’Œä¼˜ç¼ºç‚¹",
        "è§£é‡Š{entity}çš„å®šä¹‰ã€ç‰¹ç‚¹å’Œä½¿ç”¨æ¡ä»¶",
        "è¯´æ˜{entity}çš„ç»“æ„ç»„æˆå’Œæ“ä½œæ–¹æ³•",
        "æè¿°{entity}çš„æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦ç‰¹æ€§",
        "åˆ†æ{entity}çš„æ ¸å¿ƒç®—æ³•æ€æƒ³",
        "ä»‹ç»{entity}çš„å…¸å‹å®ç°æ–¹å¼",
        "é˜è¿°{entity}åœ¨å®é™…é¡¹ç›®ä¸­çš„ä»·å€¼"
    ]
    
    # æ“ä½œå‹æ¨¡æ¿ (20%)
    operation_templates = [
        "æè¿°åœ¨{entity}ä¸­è¿›è¡Œ{operation}æ“ä½œçš„å…·ä½“æ­¥éª¤",
        "è¯´æ˜{entity}è¿›è¡Œ{operation}æ—¶éœ€è¦æ³¨æ„çš„é—®é¢˜",
        "è§£é‡Š{entity}çš„{operation}æ“ä½œå®ç°æœºåˆ¶",
        "åˆ†æ{entity}ä¸­{operation}æ“ä½œçš„æ—¶é—´å¤æ‚åº¦",
        "ä»‹ç»{entity}çš„{operation}è¿‡ç¨‹å’Œä¼˜åŒ–æ–¹æ³•"
    ]
    
    # åº”ç”¨åœºæ™¯å‹æ¨¡æ¿ (10%)
    application_templates = [
        "åˆ†æ{entity}åœ¨{scenario}é¢†åŸŸçš„æŠ€æœ¯ä¼˜åŠ¿",
        "è§£é‡Š{entity}å¦‚ä½•è§£å†³{scenario}ä¸­çš„å…³é”®é—®é¢˜",
        "æè¿°{entity}åœ¨{scenario}ç³»ç»Ÿä¸­çš„æ ¸å¿ƒä½œç”¨",
        "è¯´æ˜{entity}åœ¨{scenario}é¡¹ç›®ä¸­çš„å®é™…åº”ç”¨"
    ]
    
    prompts = []
    
    # è®¡ç®—å„ç±»å‹æ•°é‡
    relation_count = int(num_records * 0.4)
    entity_count = int(num_records * 0.3)
    operation_count = int(num_records * 0.2)
    remaining_count = num_records - relation_count - entity_count - operation_count
    
    # ç”Ÿæˆå…³ç³»å‹æç¤ºè¯
    for _ in range(relation_count):
        template = random.choice(relation_templates)
        entities = random.sample([e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities], 2)
        prompt = template.format(entity1=entities[0], entity2=entities[1])
        prompts.append(prompt)
    
    # ç”Ÿæˆå®ä½“æè¿°å‹æç¤ºè¯
    for _ in range(entity_count):
        template = random.choice(entity_templates)
        entity = random.choice([e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities])
        prompt = template.format(entity=entity)
        prompts.append(prompt)
    
    # ç”Ÿæˆæ“ä½œå‹æç¤ºè¯
    for _ in range(operation_count):
        template = random.choice(operation_templates)
        entity = random.choice([e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities])
        operation = random.choice(KNOWLEDGE_GRAPH_BASE["æ“ä½œç±»å‹"])
        prompt = template.format(entity=entity, operation=operation)
        prompts.append(prompt)
    
    # ç”Ÿæˆåº”ç”¨åœºæ™¯å‹æç¤ºè¯
    for _ in range(remaining_count):
        template = random.choice(application_templates)
        entity = random.choice([e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities])
        scenario = random.choice(KNOWLEDGE_GRAPH_BASE["åº”ç”¨åœºæ™¯"])
        prompt = template.format(entity=entity, scenario=scenario)
        prompts.append(prompt)
    
    random.shuffle(prompts)
    return prompts

def is_valid_kg_response(text):
    """éªŒè¯å“åº”æ˜¯å¦é€‚åˆçŸ¥è¯†å›¾è°±æ„å»º"""
    if not text or len(text.strip()) < 15:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ€æœ¯å®ä½“
    all_entities = [e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities]
    has_entity = any(entity in text for entity in all_entities)
    
    # æ£€æŸ¥æ— æ•ˆæ¨¡å¼
    invalid_patterns = [
        r'æˆ‘æ— æ³•|æˆ‘ä¸èƒ½|æŠ±æ­‰|å¯¹ä¸èµ·',
        r'ä½œä¸ºAI|ä½œä¸ºè¯­è¨€æ¨¡å‹',
        r'è¯·æ³¨æ„|éœ€è¦æ³¨æ„çš„æ˜¯',
        r'^\s*$',
        r'^[^ã€‚ï¼ï¼Ÿ]*$'
    ]
    
    for pattern in invalid_patterns:
        if re.search(pattern, text):
            return False
    
    return has_entity and 15 <= len(text) <= 250

def call_api_with_retry(prompt):
    """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
    client = create_client()
    
    for attempt in range(Config.RETRY_COUNT):
        try:
            if Config.DELAY_BETWEEN_REQUESTS > 0:
                time.sleep(Config.DELAY_BETWEEN_REQUESTS)
            
            response = client.chat.completions.create(
                model=Config.MODEL,
                messages=[
                    {"role": "system", "content": "ç”Ÿæˆå‡†ç¡®å®Œæ•´çš„è®¡ç®—æœºæŠ€æœ¯æè¿°ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            
            if is_valid_kg_response(content):
                return content
            else:
                continue
                
        except Exception as e:
            if attempt == Config.RETRY_COUNT - 1:
                logging.warning(f"APIè°ƒç”¨æœ€ç»ˆå¤±è´¥: {e}")
                return None
            logging.debug(f"APIè°ƒç”¨é‡è¯• {attempt + 1}/{Config.RETRY_COUNT}: {e}")
            time.sleep(0.5)  # å‡å°‘é‡è¯•å»¶è¿Ÿ
    
    return None

def post_process_sentences(sentences):
    """æ•°æ®åå¤„ç†ä¼˜åŒ–"""
    print("\nğŸ”§ æ­£åœ¨è¿›è¡Œæ•°æ®åå¤„ç†ä¼˜åŒ–...")
    
    processed = []
    for sentence in sentences:
        # æ¸…ç†ç©ºæ ¼å’Œæ ‡ç‚¹
        cleaned = re.sub(r'\s+', ' ', sentence.strip())
        cleaned = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹]+$', '', cleaned)
        
        # ç¡®ä¿ä»¥å¥å·ç»“å°¾
        if not cleaned.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')):
            cleaned += 'ã€‚'
        
        # é•¿åº¦å’Œè´¨é‡æ£€æŸ¥
        if 15 <= len(cleaned) <= 250:
            all_entities = [e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities]
            if any(entity in cleaned for entity in all_entities):
                processed.append(cleaned)
    
    print(f"âœ… åå¤„ç†å®Œæˆ: ä¿ç•™ {len(processed)} æ¡ï¼Œç§»é™¤ {len(sentences) - len(processed)} æ¡")
    return processed

def process_large_batch(prompts):
    """æ‰¹é‡å¤„ç†æç¤ºè¯ï¼Œå®æ—¶ä¿å­˜æ•°æ®"""
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(prompts)} æ¡æ•°æ®...")
    
    results = []
    batch_size = 50  # æ¯50æ¡æ•°æ®ä¿å­˜ä¸€æ¬¡
    temp_results = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=Config.CONCURRENCY) as executor:
        future_to_prompt = {executor.submit(call_api_with_retry, prompt): prompt for prompt in prompts}
        
        with tqdm(total=len(prompts), desc="ç”Ÿæˆæ•°æ®", unit="æ¡") as pbar:
            for future in concurrent.futures.as_completed(future_to_prompt):
                result = future.result()
                if result:
                    temp_results.append(result)
                    
                    # æ¯è¾¾åˆ°batch_sizeå°±ä¿å­˜ä¸€æ¬¡
                    if len(temp_results) >= batch_size:
                        processed_batch = post_process_sentences(temp_results)
                        save_batch_data(processed_batch, Config.OUTPUT_FILE)
                        results.extend(processed_batch)
                        temp_results = []
                        
                pbar.update(1)
    
    # ä¿å­˜å‰©ä½™æ•°æ®
    if temp_results:
        processed_batch = post_process_sentences(temp_results)
        save_batch_data(processed_batch, Config.OUTPUT_FILE)
        results.extend(processed_batch)
    
    # å»é‡
    unique_results = list(set(results))
    print(f"âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆ: {len(unique_results)} æ¡æœ‰æ•ˆæ•°æ®")
    return unique_results

def analyze_data_quality(sentences):
    """åˆ†æç”Ÿæˆæ•°æ®çš„è´¨é‡"""
    print("\nğŸ“Š æ•°æ®è´¨é‡åˆ†æ:")
    
    all_entities = [e for entities in KNOWLEDGE_GRAPH_BASE.values() for e in entities]
    
    # ç»Ÿè®¡å®ä½“è¦†ç›–ç‡
    entity_mentions = Counter()
    for sentence in sentences:
        for entity in all_entities:
            if entity in sentence:
                entity_mentions[entity] += 1
    
    covered_entities = len(entity_mentions)
    total_entities = len(all_entities)
    coverage_rate = (covered_entities / total_entities) * 100
    
    print(f"ğŸ¯ å®ä½“è¦†ç›–ç‡: {covered_entities}/{total_entities} ({coverage_rate:.1f}%)")
    
    # ç»Ÿè®¡å…³ç³»è¯å‡ºç°é¢‘ç‡
    relation_words = ['æ˜¯', 'æœ‰', 'å…·æœ‰', 'åŒ…å«', 'å±äº', 'ç”¨äº', 'å¯ä»¥', 'èƒ½å¤Ÿ', 'å®ç°', 'æ”¯æŒ', 'é‡‡ç”¨']
    relation_counts = Counter()
    for sentence in sentences:
        for word in relation_words:
            if word in sentence:
                relation_counts[word] += 1
    
    print(f"ğŸ”— å…³ç³»è¯åˆ†å¸ƒ: {dict(relation_counts.most_common(5))}")
    
    # ç»Ÿè®¡å¥å­é•¿åº¦åˆ†å¸ƒ
    lengths = [len(sentence) for sentence in sentences]
    print(f"ğŸ“ å¥å­é•¿åº¦: å¹³å‡{sum(lengths)/len(lengths):.1f}å­—, èŒƒå›´{min(lengths)}-{max(lengths)}å­—")
    
    return {
        'entity_coverage': coverage_rate,
        'covered_entities': covered_entities,
        'relation_distribution': dict(relation_counts),
        'avg_length': sum(lengths)/len(lengths),
        'length_range': (min(lengths), max(lengths))
    }

def save_batch_data(sentences, filename):
    """å®æ—¶ä¿å­˜æ‰¹é‡æ•°æ®åˆ°æ–‡ä»¶"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'a', encoding='utf-8') as f:
            for sentence in sentences:
                f.write(sentence + '\n')
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(sentences)} æ¡æ•°æ®")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def save_data(sentences, filename):
    """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
    try:
        # å¦‚æœæ˜¯æœ€ç»ˆä¿å­˜ï¼Œåˆ†ææ•°æ®è´¨é‡
        quality_report = analyze_data_quality(sentences)
        return quality_report
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥APIå¯†é’¥
    if not Config.API_KEY:
        print("âŒ é”™è¯¯: è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ ARK_API_KEY")
        return
    
    print("ğŸš€ çŸ¥è¯†å›¾è°±æ•°æ®ç”Ÿæˆå™¨å¯åŠ¨")
    print(f"ğŸ“‹ ç›®æ ‡: ç”Ÿæˆ {Config.NUM_RECORDS} æ¡é«˜è´¨é‡è®­ç»ƒæ•°æ®")
    print(f"âš™ï¸ é…ç½®: å¹¶å‘æ•° {Config.CONCURRENCY}, è¶…æ—¶ {Config.TIMEOUT}s")
    start_time = time.time()
    
    try:
        # ç”Ÿæˆæç¤ºè¯
        print(f"\nğŸ”§ ç”Ÿæˆ {Config.NUM_RECORDS} ä¸ªä¼˜åŒ–æç¤ºè¯...")
        prompts = generate_kg_optimized_prompts(Config.NUM_RECORDS)
        
        # æ‰¹é‡ç”Ÿæˆæ•°æ®
        sentences = process_large_batch(prompts)
        
        if not sentences:
            print("âŒ æœªç”Ÿæˆä»»ä½•æœ‰æ•ˆæ•°æ®")
            return
        
        # ä¿å­˜æ•°æ®é›†
        print(f"\nğŸ’¾ ä¿å­˜æ•°æ®é›†...")
        quality_report = save_data(sentences, Config.OUTPUT_FILE)
        
        # å®Œæˆæç¤º
        end_time = time.time()
        print(f"\nğŸ‰ æ•°æ®ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {len(sentences)} æ¡é«˜è´¨é‡æ•°æ®")
        print(f"ğŸ¯ å®ä½“è¦†ç›–ç‡: {quality_report['entity_coverage']:.1f}%")
        print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"âš¡ å¹³å‡é€Ÿåº¦: {len(sentences)/(end_time - start_time):.1f} æ¡/ç§’")
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {Config.OUTPUT_FILE}")
        print(f"ğŸ’¡ å»ºè®®: æ•°æ®å¯ç›´æ¥ç”¨äºçŸ¥è¯†å›¾è°±æ¨¡å‹è®­ç»ƒ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
        logging.error(f"ç¨‹åºå¼‚å¸¸: {e}")

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('knowledge_generator.log'),
            logging.StreamHandler()
        ]
    )
    
    main()